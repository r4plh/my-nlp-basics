{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"hi , I am Aman Agrawal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipe_names) # default component on the doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x14dbc3ad0>), ('tagger', <spacy.pipeline.tagger.Tagger object at 0x14d6cec30>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x14dbca030>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x14df7df10>), ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer object at 0x14d65b010>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x14dbca260>)]\n"
     ]
    }
   ],
   "source": [
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.length_function(doc)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"length_component\")\n",
    "def length_function(doc):\n",
    "    print(f\"Length of the token : {len(doc)}\")\n",
    "\n",
    "    return doc \n",
    "\n",
    "nlp.add_pipe(\"length_component\" , first = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the token : 3\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"Hi am studying\") # coz custom funnction that we made was for printing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['length_component',\n",
       " 'tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the token : 9\n",
      "Golden Retriver\n"
     ]
    }
   ],
   "source": [
    "# Revision of mathcer and Phrase Matcher\n",
    "from spacy.matcher import Matcher , PhraseMatcher\n",
    "\n",
    "doc = nlp(\"I love dogs and Golden Retriver are my favs\")\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"DOG_by_Matcher\" , [[{\"LOWER\": \"golden\"}, {\"LOWER\": \"retriver\"}]])\n",
    "\n",
    "for match_id , start , end in matcher(doc):\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the token : 2\n"
     ]
    }
   ],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab) # in Phrase matcher instead of dict , doc object is given in argument\n",
    "matcher.add(\"DOG_by_PM\" , [nlp(\"golden retriver\")])\n",
    "\n",
    "for match_id , start , end in matcher(doc):\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the token : 2\n",
      "Golden Retriver\n"
     ]
    }
   ],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab) # in Phrase matcher instead of dict , doc object is given in argument\n",
    "matcher.add(\"DOG_by_PM\" , [nlp(\"Golden Retriver\")])\n",
    "\n",
    "for match_id , start , end in matcher(doc):\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/Users/0xr4plh/Documents/Machine Learning/my-nlp-basics/spaCy/Code/countries.json\" , encoding=\"utf8\") as f:\n",
    "    COUNTRIES = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Afghanistan',\n",
       " 'Åland Islands',\n",
       " 'Albania',\n",
       " 'Algeria',\n",
       " 'American Samoa',\n",
       " 'Andorra',\n",
       " 'Angola',\n",
       " 'Anguilla',\n",
       " 'Antarctica',\n",
       " 'Antigua and Barbuda']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COUNTRIES[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Language.pipe at 0x14c557e10>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe(COUNTRIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Afghanistan,\n",
       " Åland Islands,\n",
       " Albania,\n",
       " Algeria,\n",
       " American Samoa,\n",
       " Andorra,\n",
       " Angola,\n",
       " Anguilla,\n",
       " Antarctica,\n",
       " Antigua and Barbuda,\n",
       " Argentina,\n",
       " Armenia,\n",
       " Aruba,\n",
       " Australia,\n",
       " Austria,\n",
       " Azerbaijan,\n",
       " Bahamas,\n",
       " Bahrain,\n",
       " Bangladesh,\n",
       " Barbados,\n",
       " Belarus,\n",
       " Belgium,\n",
       " Belize,\n",
       " Benin,\n",
       " Bermuda,\n",
       " Bhutan,\n",
       " Bolivia (Plurinational State of),\n",
       " Bonaire, Sint Eustatius and Saba,\n",
       " Bosnia and Herzegovina,\n",
       " Botswana,\n",
       " Bouvet Island,\n",
       " Brazil,\n",
       " British Indian Ocean Territory,\n",
       " United States Minor Outlying Islands,\n",
       " Virgin Islands (British),\n",
       " Virgin Islands (U.S.),\n",
       " Brunei Darussalam,\n",
       " Bulgaria,\n",
       " Burkina Faso,\n",
       " Burundi,\n",
       " Cambodia,\n",
       " Cameroon,\n",
       " Canada,\n",
       " Cabo Verde,\n",
       " Cayman Islands,\n",
       " Central African Republic,\n",
       " Chad,\n",
       " Chile,\n",
       " China,\n",
       " Christmas Island,\n",
       " Cocos (Keeling) Islands,\n",
       " Colombia,\n",
       " Comoros,\n",
       " Congo,\n",
       " Congo (Democratic Republic of the),\n",
       " Cook Islands,\n",
       " Costa Rica,\n",
       " Croatia,\n",
       " Cuba,\n",
       " Curaçao,\n",
       " Cyprus,\n",
       " Czech Republic,\n",
       " Denmark,\n",
       " Djibouti,\n",
       " Dominica,\n",
       " Dominican Republic,\n",
       " Ecuador,\n",
       " Egypt,\n",
       " El Salvador,\n",
       " Equatorial Guinea,\n",
       " Eritrea,\n",
       " Estonia,\n",
       " Ethiopia,\n",
       " Falkland Islands (Malvinas),\n",
       " Faroe Islands,\n",
       " Fiji,\n",
       " Finland,\n",
       " France,\n",
       " French Guiana,\n",
       " French Polynesia,\n",
       " French Southern Territories,\n",
       " Gabon,\n",
       " Gambia,\n",
       " Georgia,\n",
       " Germany,\n",
       " Ghana,\n",
       " Gibraltar,\n",
       " Greece,\n",
       " Greenland,\n",
       " Grenada,\n",
       " Guadeloupe,\n",
       " Guam,\n",
       " Guatemala,\n",
       " Guernsey,\n",
       " Guinea,\n",
       " Guinea-Bissau,\n",
       " Guyana,\n",
       " Haiti,\n",
       " Heard Island and McDonald Islands,\n",
       " Holy See,\n",
       " Honduras,\n",
       " Hong Kong,\n",
       " Hungary,\n",
       " Iceland,\n",
       " India,\n",
       " Indonesia,\n",
       " Côte d'Ivoire,\n",
       " Iran (Islamic Republic of),\n",
       " Iraq,\n",
       " Ireland,\n",
       " Isle of Man,\n",
       " Israel,\n",
       " Italy,\n",
       " Jamaica,\n",
       " Japan,\n",
       " Jersey,\n",
       " Jordan,\n",
       " Kazakhstan,\n",
       " Kenya,\n",
       " Kiribati,\n",
       " Kuwait,\n",
       " Kyrgyzstan,\n",
       " Lao People's Democratic Republic,\n",
       " Latvia,\n",
       " Lebanon,\n",
       " Lesotho,\n",
       " Liberia,\n",
       " Libya,\n",
       " Liechtenstein,\n",
       " Lithuania,\n",
       " Luxembourg,\n",
       " Macao,\n",
       " Macedonia (the former Yugoslav Republic of),\n",
       " Madagascar,\n",
       " Malawi,\n",
       " Malaysia,\n",
       " Maldives,\n",
       " Mali,\n",
       " Malta,\n",
       " Marshall Islands,\n",
       " Martinique,\n",
       " Mauritania,\n",
       " Mauritius,\n",
       " Mayotte,\n",
       " Mexico,\n",
       " Micronesia (Federated States of),\n",
       " Moldova (Republic of),\n",
       " Monaco,\n",
       " Mongolia,\n",
       " Montenegro,\n",
       " Montserrat,\n",
       " Morocco,\n",
       " Mozambique,\n",
       " Myanmar,\n",
       " Namibia,\n",
       " Nauru,\n",
       " Nepal,\n",
       " Netherlands,\n",
       " New Caledonia,\n",
       " New Zealand,\n",
       " Nicaragua,\n",
       " Niger,\n",
       " Nigeria,\n",
       " Niue,\n",
       " Norfolk Island,\n",
       " Korea (Democratic People's Republic of),\n",
       " Northern Mariana Islands,\n",
       " Norway,\n",
       " Oman,\n",
       " Pakistan,\n",
       " Palau,\n",
       " Palestine, State of,\n",
       " Panama,\n",
       " Papua New Guinea,\n",
       " Paraguay,\n",
       " Peru,\n",
       " Philippines,\n",
       " Pitcairn,\n",
       " Poland,\n",
       " Portugal,\n",
       " Puerto Rico,\n",
       " Qatar,\n",
       " Republic of Kosovo,\n",
       " Réunion,\n",
       " Romania,\n",
       " Russian Federation,\n",
       " Rwanda,\n",
       " Saint Barthélemy,\n",
       " Saint Helena, Ascension and Tristan da Cunha,\n",
       " Saint Kitts and Nevis,\n",
       " Saint Lucia,\n",
       " Saint Martin (French part),\n",
       " Saint Pierre and Miquelon,\n",
       " Saint Vincent and the Grenadines,\n",
       " Samoa,\n",
       " San Marino,\n",
       " Sao Tome and Principe,\n",
       " Saudi Arabia,\n",
       " Senegal,\n",
       " Serbia,\n",
       " Seychelles,\n",
       " Sierra Leone,\n",
       " Singapore,\n",
       " Sint Maarten (Dutch part),\n",
       " Slovakia,\n",
       " Slovenia,\n",
       " Solomon Islands,\n",
       " Somalia,\n",
       " South Africa,\n",
       " South Georgia and the South Sandwich Islands,\n",
       " Korea (Republic of),\n",
       " South Sudan,\n",
       " Spain,\n",
       " Sri Lanka,\n",
       " Sudan,\n",
       " Suriname,\n",
       " Svalbard and Jan Mayen,\n",
       " Swaziland,\n",
       " Sweden,\n",
       " Switzerland,\n",
       " Syrian Arab Republic,\n",
       " Taiwan,\n",
       " Tajikistan,\n",
       " Tanzania, United Republic of,\n",
       " Thailand,\n",
       " Timor-Leste,\n",
       " Togo,\n",
       " Tokelau,\n",
       " Tonga,\n",
       " Trinidad and Tobago,\n",
       " Tunisia,\n",
       " Turkey,\n",
       " Turkmenistan,\n",
       " Turks and Caicos Islands,\n",
       " Tuvalu,\n",
       " Uganda,\n",
       " Ukraine,\n",
       " United Arab Emirates,\n",
       " United Kingdom of Great Britain and Northern Ireland,\n",
       " United States of America,\n",
       " Uruguay,\n",
       " Uzbekistan,\n",
       " Vanuatu,\n",
       " Venezuela (Bolivarian Republic of),\n",
       " Viet Nam,\n",
       " Wallis and Futuna,\n",
       " Western Sahara,\n",
       " Yemen,\n",
       " Zambia,\n",
       " Zimbabwe]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nlp.pipe(COUNTRIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Czech Republic, Slovakia]\n"
     ]
    }
   ],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "patterns = list(nlp.pipe(COUNTRIES))\n",
    "matcher.add(\"BY_PM_COUNTRIES\" , patterns)\n",
    "\n",
    "doc = nlp(\"Czech Republic may help Slovakia protect its airspace\")\n",
    "\n",
    "matches = matcher(doc)\n",
    "print([doc[start:end] for match_id, start, end in matches]) # case sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPE Namibia\n",
      "GPE South Africa\n",
      "GPE Cambodia\n",
      "GPE Kuwait\n",
      "GPE Somalia\n",
      "GPE Haiti\n",
      "GPE Mozambique\n",
      "GPE Somalia\n",
      "GPE Rwanda\n",
      "GPE Singapore\n",
      "GPE Sierra Leone\n",
      "GPE Afghanistan\n",
      "GPE Iraq\n",
      "GPE Sudan\n",
      "GPE Congo\n",
      "GPE Haiti\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Span\n",
    "\n",
    "with open(\"/Users/0xr4plh/Documents/Machine Learning/my-nlp-basics/spaCy/Code/countries.json\" , encoding=\"utf8\") as f:\n",
    "    COUNTRIES = json.loads(f.read())\n",
    "\n",
    "with open(\"/Users/0xr4plh/Documents/Machine Learning/my-nlp-basics/spaCy/Code/country_text.txt\" , encoding=\"utf8\") as f:\n",
    "    TEXT = f.read()\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "matcher.add(\"match\" , list(nlp.pipe(COUNTRIES)))\n",
    "\n",
    "doc = nlp(TEXT)\n",
    "\n",
    "doc.ents = []\n",
    "\n",
    "for match_id , start , end in matcher(doc):\n",
    "    span = Span(doc , start , end , label = \"GPE\")\n",
    "    doc.ents = list(doc.ents) + [span]\n",
    "\n",
    "    root = span.root\n",
    "    head = span.root.head\n",
    "    # print(f\"Head of span - {head}\")\n",
    "\n",
    "for token in doc.ents:\n",
    "    print(token.label_ , token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner', 'animal']\n",
      "[('cat', 'ANIMAL'), ('Golden Retriever', 'ANIMAL')]\n"
     ]
    }
   ],
   "source": [
    "# In this exercise, you’ll be writing a custom component that uses the PhraseMatcher to find animal names in the document and adds the matched spans to the doc.ents. A PhraseMatcher with the animal patterns has already been created as the variable matcher.\n",
    "\n",
    "# Define the custom component and apply the matcher to the doc.\n",
    "# Create a Span for each match, assign the label ID for \"ANIMAL\" and overwrite the doc.ents with the new spans.\n",
    "# Add the new component to the pipeline after the \"ner\" component.\n",
    "# Process the text and print the entity text and entity label for the entities in doc.ents.\n",
    "\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "animals = [\"Golden Retriever\", \"cat\", \"turtle\", \"Rattus norvegicus\"]\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "matcher.add(\"animal_matching\" , list(nlp.pipe(animals)))\n",
    "\n",
    "@Language.component(\"animal\")\n",
    "def animal_matcher(doc):\n",
    "\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    # [list(doc.ents) + [Span(doc , start , end , label = \"ANIMAL\")] for match_id , start , end in matches] -> incorrect\n",
    "\n",
    "    spans = [Span(doc, start, end, label=\"ANIMAL\") for match_id, start, end in matches]\n",
    "\n",
    "    doc.ents = spans\n",
    "\n",
    "    return doc \n",
    "\n",
    "nlp.add_pipe(\"animal\" , after = \"ner\") # in this it's after ner so , doc.ents got re-initialized and old new data got vanished\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "doc = nlp(\"I have a cat and a Golden Retriever , I like New York city and I work in SV company\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 'ANIMAL'), ('Golden Retriever', 'ANIMAL'), ('New York', 'GPE'), ('SV', 'GPE')]\n"
     ]
    }
   ],
   "source": [
    "# added before ner\n",
    "\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "animals = [\"Golden Retriever\", \"cat\", \"turtle\", \"Rattus norvegicus\"]\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "matcher.add(\"animal_matching\" , list(nlp.pipe(animals)))\n",
    "\n",
    "@Language.component(\"animal\")\n",
    "def animal_matcher(doc):\n",
    "\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    # [list(doc.ents) + [Span(doc , start , end , label = \"ANIMAL\")] for match_id , start , end in matches] -> incorrect\n",
    "\n",
    "    spans = [Span(doc, start, end, label=\"ANIMAL\") for match_id, start, end in matches]\n",
    "\n",
    "    doc.ents = spans\n",
    "\n",
    "    return doc \n",
    "\n",
    "nlp.add_pipe(\"animal\" , before = \"ner\") # in this it's before ner so , so from here doc.ents was made and then sent to ner so now will contain both custom + default ner also\n",
    "\n",
    "doc = nlp(\"I have a cat and a Golden Retriever , I like New York city and I work in SV company\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes - Very Important as they provide custom attributes on Tokens , Span and docs - very powerful custom function tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extentions -> Attribute Extention , Property Extention and Method Extention\n",
    "# Attribute extention -> normal , can be over-written\n",
    "# Property extention -> Defined via getter function - takes in one argument like token\n",
    "# Method attribute -> makes callable , can take one or more arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env-3.12.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
