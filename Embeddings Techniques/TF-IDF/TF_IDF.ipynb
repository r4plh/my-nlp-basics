{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDLy1_hlSgsS",
        "outputId": "af1f79db-e89e-4afd-9860-021da39fce2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lemmatizer and stop words\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Define a function for preprocessing text\n",
        "def preprocess(text):\n",
        "    # Tokenize the text\n",
        "    words = nltk.word_tokenize(text)\n",
        "    # Lemmatize words and remove stop words and non-alpha characters\n",
        "    return ' '.join([lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in stop_words and word.isalpha()])\n",
        "\n",
        "# Example documents\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"The quick brown fox is quick.\",\n",
        "    \"Jumping foxes are quick and can jump high.\"\n",
        "]\n",
        "\n",
        "# Preprocess documents\n",
        "processed_documents = [preprocess(doc) for doc in documents]\n",
        "\n",
        "print(processed_documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYNqXmyISq9i",
        "outputId": "548e2197-7a6b-4ee1-b580-8af8d364454e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['quick brown fox jump lazy dog', 'quick brown fox quick', 'jumping fox quick jump high']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a TfidfVectorizer with no stop words option as we already handled them\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the processed documents\n",
        "tfidf_matrix = vectorizer.fit_transform(processed_documents)\n",
        "\n",
        "# Get the feature names that correspond to the columns of the tfidf matrix\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Convert the tfidf matrix to a dense format and create a DataFrame\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.todense(), columns=feature_names)\n",
        "\n",
        "print(tfidf_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsDiP4HvTT4s",
        "outputId": "203c2dd8-3f74-4704-c350-b5ea3b4adfe6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      brown       dog       fox     high      jump  jumping      lazy  \\\n",
            "0  0.387376  0.509353  0.300832  0.00000  0.387376  0.00000  0.509353   \n",
            "1  0.499037  0.000000  0.387547  0.00000  0.000000  0.00000  0.000000   \n",
            "2  0.000000  0.000000  0.326310  0.55249  0.420183  0.55249  0.000000   \n",
            "\n",
            "      quick  \n",
            "0  0.300832  \n",
            "1  0.775093  \n",
            "2  0.326310  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X8Gkk8LqTuhJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}